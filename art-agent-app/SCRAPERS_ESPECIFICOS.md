# Scrapers Espec√≠ficos - Documenta√ß√£o

## ‚úÖ STATUS: IMPLEMENTADO E FUNCIONANDO

### Scrapers Otimizados Implementados

1. **Propmark** ‚úÖ
   - URL: https://propmark.com.br
   - Status: **FUNCIONANDO**
   - √öltimo teste: 49 artigos coletados, 27 salvos
   - T√©cnicas: Headers personalizados, User-Agent, delay entre p√°ginas

2. **Meio & Mensagem** ‚úÖ  
   - URL: https://meioemensagem.com.br/comunicacao
   - Status: **FUNCIONANDO**
   - √öltimo teste: 9 artigos coletados, 6 salvos
   - T√©cnicas: M√∫ltiplos seletores CSS, parsing robusto

3. **AdNews** ‚ö†Ô∏è
   - URL: https://adnews.com.br
   - Status: **EM DESENVOLVIMENTO**
   - √öltimo teste: 0 artigos (seletores precisam ajuste)

## üöÄ Como Usar

### Via Terminal (Recomendado)

```powershell
# Executar scraping espec√≠fico
npx tsx save-scraped-final.ts
```

### Via API (Quando servidor estiver rodando)

```powershell
# M√©todo 1: PowerShell
$body = '{"useSpecificScrapers":true,"startDate":"2025-01-01"}'
Invoke-WebRequest -Uri http://localhost:3000/api/scrape-news `
  -Method POST `
  -Body $body `
  -ContentType "application/json"

# M√©todo 2: curl (se dispon√≠vel)
curl -X POST http://localhost:3000/api/scrape-news `
  -H "Content-Type: application/json" `
  -d '{"useSpecificScrapers":true,"startDate":"2025-01-01"}'
```

## üìä Resultados do √öltimo Teste

```
=== RESUMO FINAL ===
üìä Total coletado: 58 artigos
üíæ Total salvo: 33 novos artigos
üîÑ Total duplicados: 25
üìö Total no banco de dados: 888 artigos (era 820, +68 com outros testes)
```

### Breakdown por Site:
- **Propmark**: 49 coletados ‚Üí 27 salvos (22 duplicados)
- **Meio & Mensagem**: 9 coletados ‚Üí 6 salvos (3 duplicados)
- **AdNews**: 0 coletados (precisa ajustes nos seletores)

## üîß T√©cnicas Anti-Bloqueio Implementadas

1. **Headers Customizados**
   ```typescript
   'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36...'
   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9...'
   'Accept-Language': 'pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7'
   'Referer': new URL(url).origin
   ```

2. **Delays Entre Requisi√ß√µes**
   - 2 segundos entre cada p√°gina
   - Evita sobrecarga do servidor e detec√ß√£o

3. **M√∫ltiplos Seletores CSS**
   - Cada scraper tenta v√°rios seletores at√© encontrar artigos
   - Exemplo: `'.post-item', '.entry-item', '.blog-post', 'article.post'`

4. **Gest√£o de Erros**
   - Try-catch por p√°gina
   - Se uma p√°gina falha, continua nas pr√≥ximas
   - Logging detalhado para debugging

## üìÅ Arquivos Criados/Modificados

### Novos Arquivos
1. `src/lib/scrapers-especificos.ts` - Scrapers otimizados
2. `test-scrapers.ts` - Script de teste r√°pido
3. `save-scraped-final.ts` - Script para salvar no banco
4. `SCRAPERS_ESPECIFICOS.md` - Esta documenta√ß√£o

### Arquivos Modificados
1. `src/lib/db.ts` - Adicionado alias `db` para `prisma`
2. `src/app/api/scrape-news/route.ts` - Suporte para `useSpecificScrapers`

## üéØ Pr√≥ximos Passos

### Prioridade ALTA
- [ ] Corrigir scraper do AdNews (ajustar seletores CSS)
- [ ] Adicionar Mundo do Marketing
- [ ] Adicionar ABAP

### Prioridade M√âDIA
- [ ] Implementar sistema de agendamento autom√°tico (cron)
- [ ] Dashboard de monitoramento de scraping
- [ ] M√©tricas: taxa de sucesso, artigos por dia, etc.

### Prioridade BAIXA
- [ ] Rota√ß√£o de User-Agents
- [ ] Proxy rotation (se necess√°rio)
- [ ] Captcha handling (apenas se encontrar bloqueios)

## üß™ Como Testar

### Teste R√°pido (sem salvar no banco)
```powershell
npx tsx test-scrapers.ts
```

### Teste Completo (com salvamento)
```powershell
npx tsx save-scraped-final.ts
```

### Verificar Banco de Dados
```powershell
# Contar artigos por feed
npx prisma studio
# Ou via c√≥digo
node -e "const{prisma}=require('./src/lib/db');prisma.newsArticle.count().then(console.log)"
```

## ‚ö†Ô∏è Troubleshooting

### Problema: "Cannot find module '@/lib/db'"
**Solu√ß√£o**: Verificar que `tsconfig.json` tem configura√ß√£o de paths:
```json
{
  "compilerOptions": {
    "paths": {
      "@/*": ["./src/*"]
    }
  }
}
```

### Problema: "feed is required"
**Solu√ß√£o**: Scrapers agora criam feeds automaticamente com `upsert`

### Problema: Scraper retorna 0 artigos
**Solu√ß√µes**:
1. Verificar se site est√° acess√≠vel: `Invoke-WebRequest -Uri "https://site.com"`
2. Inspecionar HTML: Ver seletores CSS corretos
3. Testar com diferentes seletores no scraper
4. Adicionar mais logs para debugging

## üìö Recursos

### Documenta√ß√£o
- Cheerio: https://cheerio.js.org/
- Axios: https://axios-http.com/
- Prisma: https://www.prisma.io/docs

### Ferramentas de Desenvolvimento
- Browser DevTools ‚Üí Inspect Element ‚Üí Copy selector
- `npx prisma studio` - Interface visual do banco
- PowerShell `Select-String` - Buscar padr√µes em HTML

## üí° Dicas

1. **Sempre testar scrapers antes de rodar em produ√ß√£o**
2. **Respeitar robots.txt dos sites**
3. **N√£o fazer scraping muito frequente (m√°x 1x por hora)**
4. **Manter delays entre requisi√ß√µes (m√≠nimo 1-2 segundos)**
5. **Logar resultados para monitoramento**

---

**√öltima atualiza√ß√£o**: Janeiro 2025  
**Status**: Propmark e M&M funcionais, AdNews em desenvolvimento
