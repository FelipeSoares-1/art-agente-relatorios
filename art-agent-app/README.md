# ğŸ¨ ART Agent App - Sistema de Monitoramento de NotÃ­cias

Um sistema inteligente de coleta, processamento e enriquecimento automÃ¡tico de notÃ­cias sobre publicidade, marketing e agÃªncias. Utiliza web scraping, feeds RSS e um pipeline de processamento assÃ­ncrono para garantir a alta qualidade e precisÃ£o dos dados.

## ğŸ“‹ VisÃ£o Geral

**ART Agent App** Ã© uma aplicaÃ§Ã£o Next.js que:

- ğŸ“° **Coleta notÃ­cias** de mÃºltiplas fontes (Google News, RSS feeds, web scrapers).
- ğŸ·ï¸ **Categoriza automaticamente** usando tags configurÃ¡veis e lÃ³gica contextual.
- âœ¨ **Valida e Enriquece Dados**: Identifica notÃ­cias com datas imprecisas e usa um worker assÃ­ncrono para corrigi-las, garantindo maior acurÃ¡cia.
- ğŸ“Š **Exibe um dashboard** com filtros por perÃ­odo (24h, 7d, 15d), tags e fontes.
- â° **Agenda tarefas** de coleta, busca e enriquecimento de dados em segundo plano.

---

## ğŸ›ï¸ Arquitetura de Coleta de Dados

Para garantir tanto a velocidade da coleta quanto a precisÃ£o dos dados, o sistema utiliza uma arquitetura de processamento em 3 fases:

### Fase 1: Coleta RÃ¡pida
- **O quÃª**: Scrapers e leitores de RSS coletam novos artigos da forma mais rÃ¡pida possÃ­vel, focando em tÃ­tulo, link e data de publicaÃ§Ã£o inicial.
- **Objetivo**: Inserir um grande volume de notÃ­cias no banco de dados rapidamente para que nÃ£o se percam.

### Fase 2: ValidaÃ§Ã£o e SinalizaÃ§Ã£o
- **O quÃª**: No momento da inserÃ§Ã£o, o `NewsService` realiza uma verificaÃ§Ã£o de sanidade na data de publicaÃ§Ã£o.
- **Objetivo**: Se a data for suspeita (ex: muito antiga, no futuro, ou uma data padrÃ£o), o artigo recebe o status `PENDING_ENRICHMENT`. Caso contrÃ¡rio, recebe `PROCESSED`.

### Fase 3: Enriquecimento AssÃ­ncrono
- **O quÃª**: Um cron job executa um "worker" a cada hora. Esse worker busca por artigos com status `PENDING_ENRICHMENT`.
- **Objetivo**: Para cada artigo pendente, o worker realiza um "deep scrape" (usando Puppeteer) na URL original para encontrar a data de publicaÃ§Ã£o correta na pÃ¡gina. ApÃ³s a correÃ§Ã£o, o status do artigo Ã© atualizado para `ENRICHED`.

Este pipeline garante que o dashboard sempre tenha notÃ­cias frescas, enquanto a qualidade dos dados Ã© continuamente melhorada em segundo plano.

---

## ğŸš€ ComeÃ§ar

### PrÃ©-requisitos

- Node.js 18+
- npm ou yarn

### InstalaÃ§Ã£o

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/FelipeSoares-1/art-agente-relatorios.git
cd art-agent-app

# 2. Instale dependÃªncias
npm install

# 3. Configure as variÃ¡veis de ambiente
# Crie um arquivo .env.local na raiz e adicione a linha abaixo:
DATABASE_URL="file:./prisma/dev.db"

# 4. Configure e popule o banco de dados
# Este comando aplica as migraÃ§Ãµes e garante que o schema estÃ¡ em sincronia.
npx prisma migrate dev

# 5. Inicie o servidor de desenvolvimento
npm run dev
```

Acesse `http://localhost:3000` no seu navegador.

## ğŸ“ Estrutura do Projeto

```
src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                  # Rotas da API (Next.js)
â”‚   â”‚   â”œâ”€â”€ news/             # GET /api/news - Listar notÃ­cias
â”‚   â”‚   â”œâ”€â”€ feeds/            # GET /api/feeds - Listar feeds RSS
â”‚   â”‚   â”œâ”€â”€ tag-categories/   # GET/POST /api/tag-categories - Gerenciar tags
â”‚   â”‚   â””â”€â”€ enrich-articles/  # GET /api/enrich-articles - Endpoint do Worker
â”‚   â”œâ”€â”€ dashboard/            # PÃ¡gina do dashboard
â”‚   â””â”€â”€ page.tsx              # PÃ¡gina inicial
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ db.ts                 # Cliente Prisma (singleton)
â”‚   â”œâ”€â”€ cron-job.ts           # Agendador de todas as tarefas (cron jobs)
â”‚   â”œâ”€â”€ tag-helper.ts         # LÃ³gica de categorizaÃ§Ã£o por tags
â”‚   â”œâ”€â”€ date-validator.ts     # UtilitÃ¡rio para validar datas
â”‚   â””â”€â”€ scrapers/
â”‚       â””â”€â”€ google-news-web-scraper.ts # Scraper com Puppeteer
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ NewsService.ts        # LÃ³gica de negÃ³cio para salvar e buscar notÃ­cias
â”‚   â””â”€â”€ ScraperService.ts     # Orquestra os diferentes scrapers
â””â”€â”€ scripts/                  # Scripts de administraÃ§Ã£o e testes manuais

prisma/
â”œâ”€â”€ schema.prisma             # DefiniÃ§Ã£o do banco de dados
â””â”€â”€ migrations/               # HistÃ³rico de migraÃ§Ãµes do schema

public/                       # Arquivos estÃ¡ticos
.env.local                   # VariÃ¡veis de ambiente (NÃƒO versionado)
```

## ğŸ—„ï¸ Banco de Dados

### Modelo `NewsArticle`

- `id`: ID Ãºnico
- `title`: TÃ­tulo do artigo
- `link`: URL do artigo
- `summary`: Resumo/descriÃ§Ã£o
- `newsDate`: Data da publicaÃ§Ã£o (campo principal para filtros)
- `insertedAt`: Data de inserÃ§Ã£o no banco
- `status`: Status do artigo no pipeline de processamento. Valores possÃ­veis:
    - `PROCESSED`: Coletado com data vÃ¡lida.
    - `PENDING_ENRICHMENT`: Coletado, mas a data Ã© suspeita e aguarda correÃ§Ã£o.
    - `ENRICHED`: A data foi corrigida pelo worker.
    - `ENRICHMENT_FAILED`: O worker tentou corrigir, mas falhou.
- `feedId`: Chave estrangeira para o `RSSFeed`.
- `tags`: String JSON contendo as tags detectadas (ex: `["PrÃªmios", "Digital"]`).
- `tags`: Array JSON de tags atribuÃ­das

**TagCategory**
- `id`: ID Ãºnico
- `name`: Nome da categoria (ex: "Artplan", "PrÃªmios")
- `keywords`: JSON array de palavras-chave para detecÃ§Ã£o automÃ¡tica
- `color`: Cor hexadecimal para UI
- `enabled`: Se a tag estÃ¡ ativa

**RSSFeed**
- `id`: ID Ãºnico
- `name`: Nome do feed
- `url`: URL do feed RSS

### MigraÃ§Ãµes

Para sincronizar o schema com o banco:
```bash
npx prisma db push
```

Para regenerar Prisma Client:
```bash
npx prisma generate
```

## ğŸ”„ Componentes Principais

### 1. **Google News Web Scraper**

Usa Puppeteer para web scraping com filtros temporais (24h, 7d, 15d).

### 2. **Scrapers EspecÃ­ficos**

Coleta de sites: Propmark, Meio & Mensagem, AdNews.

### 3. **Scheduler de Feeds**

Atualiza RSS feeds a cada 30 minutos.

### 4. **Busca Ativa**

Busca automÃ¡tica em horÃ¡rios: 08:00 e 18:00.

### 5. **CategorizaÃ§Ã£o por Tags**

Detecta e atribui tags automaticamente.

## ğŸ“Š API Endpoints

### `GET /api/news`

Retorna notÃ­cias com filtros opcionais.

**Query Parameters:**
- `period`: `24h`, `7d`, `15d`
- `tag`: Nome da tag
- `feedId`: ID do feed
- `search`: Busca por texto

**Exemplo:**
```bash
curl "http://localhost:3000/api/news?period=24h&tag=Premios"
```

### `GET /api/feeds`

Lista feeds RSS.

### `GET /api/tag-categories`

Lista categorias de tags.

### `GET /api/cron-logs`

Logs de execuÃ§Ã£o de jobs.

## ğŸ·ï¸ Tags PadrÃ£o

1. **Artplan** - NotÃ­cias sobre Artplan
2. **PrÃªmios** - PrÃªmios e reconhecimentos
3. **Concorrentes** - AgÃªncias concorrentes
4. **Novos Clientes** - Conquistas de clientes
5. **Digital** - Marketing digital

## ğŸ“ Desenvolvimento

### Adicionar Feed RSS

1. `/feeds` â†’ Novo Feed
2. Cole URL RSS
3. Sistema atualiza a cada 30 min

### Adicionar Tag

1. `/tags` â†’ Nova Tag
2. Configure nome, keywords, cor
3. NotÃ­cias recategorizadas automaticamente

## ğŸ“š DocumentaÃ§Ã£o

Ver `MELHORIAS.md` para histÃ³rico de correÃ§Ãµes e melhorias.
