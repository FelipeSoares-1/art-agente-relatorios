# ğŸ¨ ART Agent App - Sistema de Monitoramento de NotÃ­cias

Um sistema inteligente de coleta, processamento e enriquecimento automÃ¡tico de notÃ­cias sobre publicidade, marketing e agÃªncias. Utiliza web scraping, feeds RSS e um pipeline de processamento assÃ­ncrono para garantir a alta qualidade e precisÃ£o dos dados.

## ğŸ“‹ VisÃ£o Geral

**ART Agent App** Ã© uma aplicaÃ§Ã£o Next.js que:

- ğŸ“° **Coleta notÃ­cias** de mÃºltiplas fontes (Google News, RSS feeds, web scrapers).
- ğŸ·ï¸ **Categoriza automaticamente** usando tags configurÃ¡veis e lÃ³gica contextual.
- ğŸ“ˆ **Apresenta uma pÃ¡gina de RelatÃ³rios** com grÃ¡ficos interativos sobre tendÃªncias de tags, menÃ§Ãµes de concorrentes e distribuiÃ§Ã£o de fontes.
- âœ¨ **Valida e Enriquece Dados**: Identifica notÃ­cias com datas imprecisas e usa um worker assÃ­ncrono para corrigi-las, garantindo maior acurÃ¡cia.
- ğŸ› ï¸ **Oferece uma pÃ¡gina de Status do Sistema** para monitorar a saÃºde dos coletores de notÃ­cias e executar aÃ§Ãµes administrativas.
- â° **Agenda tarefas** de coleta, busca e enriquecimento de dados em segundo plano.

---

## ğŸ›ï¸ Arquitetura de Coleta de Dados

Para garantir tanto a velocidade da coleta quanto a precisÃ£o dos dados, o sistema utiliza uma arquitetura de processamento em 3 fases:

### Fase 1: Coleta RÃ¡pida
- **O quÃª**: Scrapers e leitores de RSS coletam novos artigos da forma mais rÃ¡pida possÃ­vel, focando em tÃ­tulo, link e data de publicaÃ§Ã£o inicial.
- **Objetivo**: Inserir um grande volume de notÃ­cias no banco de dados rapidamente para que nÃ£o se percam.

### Fase 2: ValidaÃ§Ã£o e SinalizaÃ§Ã£o
- **O quÃª**: No momento da inserÃ§Ã£o, o `NewsService` realiza uma verificaÃ§Ã£o de sanidade na data de publicaÃ§Ã£o usando o `date-validator`.
- **Objetivo**: Se a data for suspeita (ex: muito antiga, no futuro, ou uma data padrÃ£o), o artigo recebe o status `PENDING_ENRICHMENT`. Caso contrÃ¡rio, recebe `PROCESSED`.

### Fase 3: Enriquecimento AssÃ­ncrono
- **O quÃª**: Um cron job executa um "worker" a cada hora. Esse worker busca por artigos com status `PENDING_ENRICHMENT`.
- **Objetivo**: Para cada artigo pendente, o worker realiza um "deep scrape" para obter o **conteÃºdo completo** e a data de publicaÃ§Ã£o correta. Com base no conteÃºdo completo, as **tags sÃ£o reavaliadas** para garantir maior precisÃ£o. ApÃ³s a correÃ§Ã£o e reavaliaÃ§Ã£o, o status do artigo Ã© atualizado para `ENRICHED`.

Este pipeline garante que o dashboard sempre tenha notÃ­cias frescas, enquanto a qualidade dos dados Ã© continuamente melhorada em segundo plano.

---

## ğŸš€ ComeÃ§ar

### PrÃ©-requisitos

- Node.js 18+
- npm

### InstalaÃ§Ã£o

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/FelipeSoares-1/art-agente-relatorios.git
cd art-agent-app

# 2. Instale dependÃªncias
npm install

# 3. Configure as variÃ¡veis de ambiente
# Crie um arquivo .env na raiz do projeto e adicione a linha abaixo:
DATABASE_URL="file:./prisma/dev.db"

# 4. Configure e popule o banco de dados
# Este comando reseta o banco de dados, aplica as migraÃ§Ãµes e executa o seed.
# O seed popula as categorias de tags iniciais.
npm run db:reset

# 5. Inicie o servidor de desenvolvimento
npm run dev
```

Acesse `http://localhost:3000` no seu navegador.

---

## ğŸ› ï¸ Scripts NPM Essenciais

- `npm run dev`: Inicia o servidor de desenvolvimento com hot-reload.
- `npm run build`: Gera a build de produÃ§Ã£o do projeto.
- `npm run start`: Inicia um servidor de produÃ§Ã£o (requer `npm run build` antes).

### Scripts de Banco de Dados

- `npm run prisma:migrate`: Cria e aplica uma nova migraÃ§Ã£o no banco de dados.
- `npm run db:push`: Sincroniza o schema do Prisma com o banco de dados (sem criar migraÃ§Ãµes).
- `npm run db:reset`: **(Destrutivo)** Apaga o banco de dados, aplica todas as migraÃ§Ãµes e executa o `seed`. Ideal para um inÃ­cio limpo.
- `npm run db:seed`: Executa o script `prisma/seed.ts` para popular o banco com dados iniciais (ex: categorias de tags).
- `npm run prisma:studio`: Abre a interface grÃ¡fica do Prisma para visualizar e editar os dados do banco.

---

## ğŸ“ Estrutura do Projeto

```
src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                  # Rotas da API (Next.js)
â”‚   â”‚   â”œâ”€â”€ news/             # GET /api/news - Listar notÃ­cias com filtros
â”‚   â”‚   â”œâ”€â”€ feeds/            # GET/POST /api/feeds - Gerenciar feeds RSS
â”‚   â”‚   â”œâ”€â”€ tag-categories/   # GET/POST /api/tag-categories - Gerenciar tags
â”‚   â”‚   â””â”€â”€ enrich-articles/  # GET /api/enrich-articles - Endpoint do Worker
â”‚   â”‚   â””â”€â”€ reports/          # Endpoints para os grÃ¡ficos de relatÃ³rios
â”‚   â”œâ”€â”€ dashboard/            # PÃ¡gina de Status do Sistema
â”‚   â”œâ”€â”€ reports/              # PÃ¡gina de RelatÃ³rios com grÃ¡ficos
â”‚   â””â”€â”€ page.tsx              # PÃ¡gina inicial (Feed de NotÃ­cias)
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ db.ts                 # Cliente Prisma (singleton)
â”‚   â”œâ”€â”€ cron-job.ts           # Agendador de todas as tarefas (cron jobs)
â”‚   â”œâ”€â”€ tag-helper.ts         # LÃ³gica de categorizaÃ§Ã£o por tags
â”‚   â”œâ”€â”€ date-validator.ts     # UtilitÃ¡rio para validar e sinalizar datas suspeitas
â”‚   â””â”€â”€ scrapers/
â”‚       â””â”€â”€ google-news-web-scraper.ts # Scraper com Puppeteer para deep scrape
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ NewsService.ts        # LÃ³gica de negÃ³cio para salvar, buscar e limpar notÃ­cias
â”‚   â””â”€â”€ ScraperService.ts     # Orquestra os diferentes scrapers
â””â”€â”€ scripts/                  # Scripts de administraÃ§Ã£o e testes manuais (via ts-node)

prisma/
â”œâ”€â”€ schema.prisma             # DefiniÃ§Ã£o dos modelos e do banco de dados
â”œâ”€â”€ seed.ts                   # Script para popular o banco com dados iniciais
â””â”€â”€ migrations/               # HistÃ³rico de migraÃ§Ãµes do schema

public/                       # Arquivos estÃ¡ticos
.env                          # VariÃ¡veis de ambiente (NÃƒO versionado)
```

---

## ğŸ—„ï¸ Banco de Dados (Prisma)

O schema (`prisma/schema.prisma`) define os seguintes modelos principais:

- **`NewsArticle`**: Armazena cada notÃ­cia coletada.
  - `link`: Campo `@@unique` para evitar duplicatas.
  - `newsDate`: A data da notÃ­cia, que pode ser corrigida pelo processo de enriquecimento.
  - `status`: Enum (`ArticleStatus`) que rastreia o artigo no pipeline (`PROCESSED`, `PENDING_ENRICHMENT`, `ENRICHED`).
  - `tags`: Um campo `String` que armazena um array de tags em formato JSON.
  - `summary`: O resumo da notÃ­cia, armazenado como texto puro apÃ³s a limpeza.

- **`RSSFeed`**: Armazena as fontes de notÃ­cias (feeds RSS e scrapers).

- **`TagCategory`**: Define as categorias de tags, suas palavras-chave e se estÃ£o ativas.

---

## ğŸ”„ Workflows Comuns

### Adicionar uma Nova Categoria de Tag

1.  **Via Frontend**: Acesse a pÃ¡gina `/tags`.
2.  Clique em "Adicionar Categoria".
3.  Preencha o nome, as palavras-chave (separadas por vÃ­rgula) e escolha uma cor.
4.  Ative a categoria.
5.  O sistema comeÃ§arÃ¡ a usar as novas palavras-chave para taguear notÃ­cias automaticamente.

### ForÃ§ar a AtualizaÃ§Ã£o dos Feeds

Para buscar notÃ­cias imediatamente sem esperar o cron job, vocÃª pode acionar a API manualmente:

```bash
# Use a extensÃ£o 'REST Client' no VS Code ou uma ferramenta como o Postman
GET http://localhost:3000/api/update-feeds
```

### Limpar o Banco de Dados e RecomeÃ§ar

Se precisar de um ambiente limpo, o script `db:reset` Ã© a melhor opÃ§Ã£o:

```bash
npm run db:reset
```
Isso irÃ¡ apagar todos os dados, recriar a estrutura do banco e popular as categorias de tags definidas no `seed.ts`.

### Modelo `NewsArticle`

- `id`: ID Ãºnico
- `title`: TÃ­tulo do artigo
- `link`: URL do artigo
- `summary`: Resumo/descriÃ§Ã£o
- `newsDate`: Data da publicaÃ§Ã£o (campo principal para filtros)
- `insertedAt`: Data de inserÃ§Ã£o no banco
- `status`: Status do artigo no pipeline de processamento. Valores possÃ­veis:
    - `PROCESSED`: Coletado com data vÃ¡lida.
    - `PENDING_ENRICHMENT`: Coletado, mas a data Ã© suspeita e aguarda correÃ§Ã£o.
    - `ENRICHED`: A data foi corrigida pelo worker.
    - `ENRICHMENT_FAILED`: O worker tentou corrigir, mas falhou.
- `feedId`: Chave estrangeira para o `RSSFeed`.
- `tags`: String JSON contendo as tags detectadas (ex: `["PrÃªmios", "Digital"]`).
- `tags`: Array JSON de tags atribuÃ­das

**TagCategory**
- `id`: ID Ãºnico
- `name`: Nome da categoria (ex: "Artplan", "PrÃªmios")
- `keywords`: JSON array de palavras-chave para detecÃ§Ã£o automÃ¡tica
- `color`: Cor hexadecimal para UI
- `enabled`: Se a tag estÃ¡ ativa

**RSSFeed**
- `id`: ID Ãºnico
- `name`: Nome do feed
- `url`: URL do feed RSS

### MigraÃ§Ãµes

Para sincronizar o schema com o banco:
```bash
npx prisma db push
```

Para regenerar Prisma Client:
```bash
npx prisma generate
```

## ğŸ”„ Componentes Principais

### 1. **Google News Web Scraper**

Usa Puppeteer para web scraping com filtros temporais (24h, 7d, 15d).

### 2. **Scrapers EspecÃ­ficos**

Coleta de sites: Propmark, Meio & Mensagem, AdNews.

### 3. **Scheduler de Feeds**

Atualiza RSS feeds a cada 30 minutos.

### 4. **Busca Ativa**

Busca automÃ¡tica em horÃ¡rios: 08:00 e 18:00.

### 5. **CategorizaÃ§Ã£o por Tags**

Detecta e atribui tags automaticamente.

## ğŸ“Š API Endpoints

### `GET /api/news`

Retorna notÃ­cias com filtros opcionais.

**Query Parameters:**
- `period`: `24h`, `7d`, `15d`
- `tag`: Nome da tag
- `feedId`: ID do feed
- `search`: Busca por texto

**Exemplo:**
```bash
curl "http://localhost:3000/api/news?period=24h&tag=Premios"
```

### `GET /api/feeds`

Lista feeds RSS.

### `GET /api/tag-categories`

Lista categorias de tags.

### `GET /api/cron-logs`

Logs de execuÃ§Ã£o de jobs.

## ğŸ·ï¸ Tags PadrÃ£o

1. **Artplan** - NotÃ­cias sobre Artplan
2. **PrÃªmios** - PrÃªmios e reconhecimentos
3. **Concorrentes** - AgÃªncias concorrentes
4. **Novos Clientes** - Conquistas de clientes
5. **Digital** - Marketing digital

## ğŸ“ Desenvolvimento

### Adicionar Feed RSS

1. `/feeds` â†’ Novo Feed
2. Cole URL RSS
3. Sistema atualiza a cada 30 min

### Adicionar Tag

1. `/tags` â†’ Nova Tag
2. Configure nome, keywords, cor
3. NotÃ­cias recategorizadas automaticamente

## ğŸ“š DocumentaÃ§Ã£o

Ver `MELHORIAS.md` para histÃ³rico de correÃ§Ãµes e melhorias.
